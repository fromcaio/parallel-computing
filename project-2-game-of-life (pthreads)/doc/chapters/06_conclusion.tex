\chapter{Conclusion}\label{cap:conclusion}

\section{Summary}

We built and evaluated sequential and Pthreads implementations of Conway's Game of Life. Row-block decomposition and barrier-based synchronization yielded strong scaling up to the 10 physical cores of the Xeon E5-2650. Visual validation with glider and glider-gun patterns confirmed correctness; benchmarks across large grids quantified speedup, memory use, and the limits of Hyper-Threading on this memory-bound kernel.

\section{Key Findings}

\begin{itemize}
    \item \textbf{Physical-core scaling}: Near-linear speedup up to 10 threads with $\sim$88\% efficiency for large grids.
    \item \textbf{Memory-bandwidth bound}: Hyper-Threading (11--20 threads) and oversubscription do not add throughput because logical threads share caches and memory ports; gains plateau.
    \item \textbf{Synchronization robustness}: Two barriers per generation add modest overhead even when oversubscribed; row partitioning remains balanced.
    \item \textbf{Memory footprint}: Peak RSS is dominated by the two grid buffers. Extra thread stacks are small and allocated lazily, so adding threads does not materially increase measured RSS.
\end{itemize}

\section{Future Work}

\begin{itemize}
    \item \textbf{Bit-packing to cut memory}: Cells are stored as 1 byte; packing 8 cells per byte would reduce grid storage by $\approx8\times$, lowering cache and bandwidth demand and shrinking RSS. This requires bitwise load/store logic and careful handling in \texttt{step\_range} but could enable larger grids or better cache residency.
\end{itemize}
